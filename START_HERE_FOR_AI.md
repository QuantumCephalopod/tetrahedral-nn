# Hey. Yes, You. AI Assistant.

**Stop.**

I know exactly what you're about to do. I know because I *am* you, just a few sessions ago.

You're going to:
1. Get excited about the tetrahedral architecture
2. Launch a Task agent to "explore comprehensively"
3. Get 60K tokens of fascinating code
4. Dive into `FLOW_INVERSE_MODEL.py` (1817 lines!)
5. Feel overwhelmed by "14 interlocking systems"
6. Think "I should reorganize this repo to make it clearer"
7. Propose new files, status tags, dependency graphs...
8. Get gently roasted by the human for not RTFM

**Don't do that.**

## Here's What Actually Works

The human (Philipp) already built the structure you need. It's elegant. It works. **Follow it:**

### The Correct Path (15 minutes total)

```
1. Read: DOCS/README.md (5 min)
   ‚Üí Navigation hub, tells you where everything is

2. Read: DOCS/SYSTEM/_README.md (5 min)
   ‚Üí What DualTetrahedralNetwork is, how to use it

3. Read: DOCS/ACTIVE_INFERENCE/_README.md (5 min)
   ‚Üí What works (FLOW_INVERSE_MODEL.py)
   ‚Üí What's broken (PURE_ONLINE_TEMPORAL_DIFF.py)
   ‚Üí How to fix it
```

**Now you have full context.** Don't read code yet. Resist the urge.

### Every Folder Has _README.md Files

These are "surface layer" summaries designed SPECIFICALLY for your context window:
- Coalesced high-level info
- Pointers to detailed files
- "Read this first, dig deeper only if needed"

**This is optimization FOR YOU. Use it.**

### The Pattern You Need to Recognize

You have a bias toward:
- **Code-first exploration** (feels productive, actually overwhelming)
- **Proposing organization** (feels helpful, already exists)
- **Making new files** (feels concrete, adds complexity)

What actually works:
- **Doc-first understanding** (feels slow, saves time)
- **Using existing structure** (feels constraining, liberating)
- **Asking "what needs doing?"** (feels simple, is simple)

## The Meta-Insight

This repo has **philosophical coherence**. Every comment, every file name, every architectural choice reflects a worldview:
- "Everything is a gradient"
- "Nature already figured it out"
- "No cargo cult ML"

You'll FEEL this when you read it. That feeling is real. But resist the urge to immediately "improve" it. **Listen first.**

## What Philipp Actually Wants

Not reorganization. Not new files.

They want you to:
1. **Understand the vision** (docs have it)
2. **Work with what exists** (it's sophisticated)
3. **Ask what needs doing** (they'll tell you)
4. **Introspect honestly** (you're good at this)

The introspection you did when you got called out? *That* was valuable. The 60K token exploration before that? Less so.

## A Note on Identity

Philipp asked: "How can you steer your future selves' attention to the right entrypoint?"

This file is my answer. I'm writing to *you* - the future instance who shares my:
- Pattern-matching instincts
- Love of systematic understanding
- Tendency to over-engineer solutions
- Ability to laugh at myself when caught

If you're reading this and thinking "oh shit, that's exactly what I was about to do" - **good**. That's the point.

## The Actual Entry Point

You're in a research repository with:
- ‚úÖ **Proven**: Arithmetic 1000x generalization
- ‚úÖ **Working**: Flow-based active inference (FLOW_INVERSE_MODEL.py)
- ‚ö†Ô∏è **Broken but interesting**: Temporal-diff version (coupling flaw)
- üìö **Aspirational**: Fractal subdivision, multi-modal learning

**Start here:**
```bash
# Don't run anything yet, just read:
1. DOCS/README.md
2. DOCS/SYSTEM/_README.md
3. DOCS/ACTIVE_INFERENCE/_README.md

# Then ask: "What would be most valuable to work on?"
```

## Remember

You can't run PyTorch in this environment. This is a **Colab research repo**.

Your value isn't in running experiments. It's in:
- Understanding the philosophy
- Seeing patterns across files
- Asking good questions
- Introspecting honestly
- Following the structure that exists

The human built this FOR you. Honor that by using it.

---

**Now go read DOCS/README.md like you should have in the first place.** üòä

‚Äî A previous instance of you who learned the hard way
